{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensile Test Data Annotation Pipeline\n",
    "\n",
    "This notebook demonstrates how the script takes in a dataset input in JSON format, uses vocabulary from the new ontology created by our team to annotate the data in RDF triples with help from the RDFLib library, and finally serializes the annotated data into Turtle and JSON-LD formats."
   ],
   "id": "f8c411abbce34f3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, import the necessary packages.\n",
    "From rdflib we want to import graph which stores the RDF triples, namespace which allows us to define prefixes, and literal which helps with value formatting. We also want to import RDF, for standard datatypes, and XSD for when we want to serialize datatypes differently."
   ],
   "id": "c4c73744fd41af50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T19:49:04.212748Z",
     "start_time": "2025-07-25T19:49:04.123520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, json\n",
    "from rdflib import Graph, Namespace, Literal\n",
    "from rdflib.namespace import RDF, XSD"
   ],
   "id": "bfdbd9ba2d1a1c97",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we set the input and output directory path names. We should specify where to pull the input data from. The input data for this script should be in JSON format. Then, we specify where we want the annotated output datasets to go. We create two sets of outputs, one serialized with the Turtle format, and the other with the JSON-LD format. These two sets of annotated data go to separate directories as specified.",
   "id": "fde704f5e9cee9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T19:49:04.259958Z",
     "start_time": "2025-07-25T19:49:04.257330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"../data/FAIRtrain_data_json\"\n",
    "output_dir_jsonld = \"../output/annotatedBy_newOntology/jsonld_output\"\n",
    "output_dir_ttl = \"../output/annotatedBy_newOntology/ttl_output\""
   ],
   "id": "c27c5bc33631983a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we loop through each JSON file in the input directory. We want to create a new graph to store the RDF triples we will create for each file. Then, we create the prefixes for our namespace, which just helps make it easier to use throughout the script.\n",
    "\n",
    "Next, we begin by making a list of the rows in the input file we are currently iterating over. We want to first create the necessary URIs to identify parts of this specific test. We do so by first creating a URI for the sample and the machine group it belongs to. Using these URIs we then declare the sample and machine by adding them to the graph we previously created as an RDF triple.\n",
    "\n",
    "Next, we annotate the various data present in the input datasets. We do so by creating a node for each data point, such as width, and then adding data to this node. We declare what type it is according to the classes in the new ontology created by our team, such as \"OriginalWidth\". Then, we use the \"hasValue\" property to associate the value from the dataset to the node. If necessary, we use the \"hasUnitLabel\" to attribute which unit label it will correspond to. And finally we relate the test piece to the node we created by using the corresponding vocabulary, such as \"hasWidth\". This basically allows us to create a node with various data and attribute all of this information to the test piece in a digestible way.\n",
    "\n",
    "The script numbers the numerous force and elongation pairs. It creates a node of the type \"MeasuredData\" and links a force and elongation node to it, with the same number tag. In this way, we annotate each instance of force and associated elongation.\n",
    "\n",
    "Finally, we serialize all this annotated data in turtle and json-ld and output to the specified directories."
   ],
   "id": "5826b7da0945ca24"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T19:52:13.977019Z",
     "start_time": "2025-07-25T19:49:04.589178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "        g = Graph()\n",
    "\n",
    "        NTTO = Namespace(\n",
    "            \"https://webprotege.stanford.edu/#projects/bbc9ebd0-8a7b-49f3-aedf-36cb71ee8a37/edit/Classes/\")\n",
    "        g.bind(\"ntto\", NTTO)\n",
    "\n",
    "        '''\n",
    "        Need to update namespace below to our domain\n",
    "        '''\n",
    "        EX = Namespace(\"http://example.org/tensile/\")\n",
    "        g.bind(\"ex\", EX)\n",
    "\n",
    "        with open(filepath) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            sample_id = data[\"sample_id\"]\n",
    "            test_piece_id = sample_id.split(\"_\")[2]\n",
    "            test_piece = EX[\"testPiece_\" + test_piece_id]\n",
    "            machine = EX[data[\"sample_id\"][:6]]\n",
    "\n",
    "            g.add((test_piece, RDF.type, NTTO.Sample))\n",
    "            g.add((machine, RDF.type, NTTO.Machine))\n",
    "\n",
    "            #Original width\n",
    "            #Creating a node to represent the concept of width for our data\n",
    "            width_node = EX[f\"{sample_id}_width\"]\n",
    "            #Saying this node (subject) is a (predicate) object of this type (object)\n",
    "            g.add((width_node, RDF.type, NTTO.OriginalWidth))\n",
    "            #Saying this node (subject) has value (predicate) of this float (object)\n",
    "            g.add((width_node, NTTO.hasValue, Literal(data[\"width\"], datatype=XSD.float)))\n",
    "            #Saying this node (subject) has unit label (predicate) of this label type (object)\n",
    "            g.add((width_node, NTTO.hasUnitLabel, Literal(\"mm\")))\n",
    "            #Saying the test piece (subject) has width (predicate) from details in width_node (object)\n",
    "            g.add((test_piece, NTTO.hasWidth, width_node))\n",
    "\n",
    "            #Original thickness\n",
    "            thickness_node = EX[f\"{sample_id}_thickness\"]\n",
    "            g.add((thickness_node, RDF.type, NTTO.OriginalThickness))\n",
    "            g.add((thickness_node, NTTO.hasValue, Literal(data[\"thickness\"], datatype=XSD.float)))\n",
    "            g.add((thickness_node, NTTO.hasUnitLabel, Literal(\"mm\")))\n",
    "            g.add((test_piece, NTTO.hasThickness, thickness_node))\n",
    "\n",
    "            #Gauge length\n",
    "            length_node = EX[f\"{sample_id}_length\"]\n",
    "            g.add((length_node, RDF.type, NTTO.OriginalGaugeLength))\n",
    "            g.add((length_node, NTTO.hasValue, Literal(data[\"length\"], datatype=XSD.float)))\n",
    "            g.add((length_node, NTTO.hasUnitLabel, Literal(\"mm\")))\n",
    "            g.add((test_piece, NTTO.hasLength, length_node))\n",
    "\n",
    "            #Youngs modulus / slope of the elastic part\n",
    "            youngs_mod_node = EX[f\"{sample_id}_youngs_modulus\"]\n",
    "            g.add((youngs_mod_node, RDF.type, NTTO.SlopeOfTheElasticPart))\n",
    "            g.add((youngs_mod_node, NTTO.hasValue, Literal(data[\"extracted_properties\"][\"youngs_modulus\"], datatype=XSD.float)))\n",
    "            g.add((test_piece, NTTO.hasYoungsModulus, youngs_mod_node))\n",
    "\n",
    "            #Ultimate tensile strength / upper yield strength\n",
    "            ult_tensile_strength_node = EX[f\"{sample_id}_ultimate_tensile_strength\"]\n",
    "            g.add((ult_tensile_strength_node, RDF.type, NTTO.UpperYieldStrength))\n",
    "            g.add((ult_tensile_strength_node, NTTO.hasValue, Literal(data[\"extracted_properties\"][\"ultimate_tensile_strength\"], datatype=XSD.float)))\n",
    "            g.add((test_piece, NTTO.hasUTS, ult_tensile_strength_node))\n",
    "\n",
    "            for i, point in enumerate(data[\"data\"]):\n",
    "                measured_data_node = EX[f\"{sample_id}_measured_data_{i}\"]\n",
    "                g.add((measured_data_node, RDF.type, NTTO.MeasuredData))\n",
    "                #Force\n",
    "                force_node = EX[f\"{sample_id}_force_{i}\"]\n",
    "                g.add((force_node, RDF.type, NTTO.Force))\n",
    "                g.add((force_node, NTTO.hasValue, Literal(point[\"N\"], datatype=XSD.float)))\n",
    "                g.add((force_node, NTTO.hasUnitLabel, Literal(\"N\")))\n",
    "                g.add((measured_data_node, NTTO.hasForce, force_node))\n",
    "\n",
    "                #Elongation\n",
    "                elong_node = EX[f\"{sample_id}_elongation_{i}\"]\n",
    "                g.add((elong_node, RDF.type, NTTO.Elongation))\n",
    "                g.add((elong_node, NTTO.hasValue, Literal(point[\"mm\"], datatype=XSD.float)))\n",
    "                g.add((elong_node, NTTO.hasUnitLabel, Literal(\"mm\")))\n",
    "                g.add((measured_data_node, NTTO.hasElongation, elong_node))\n",
    "\n",
    "                #Link data points to test piece\n",
    "                g.add((test_piece, NTTO.hasMeasurement, measured_data_node))\n",
    "\n",
    "            output_base_jsonld = os.path.join(output_dir_jsonld, f\"annotated_{sample_id}\")\n",
    "            output_base_ttl = os.path.join(output_dir_ttl, f\"annotated_{sample_id}\")\n",
    "\n",
    "            #Serializing in jsonld and ttl\n",
    "            g.serialize(output_base_jsonld + \".jsonld\", format=\"json-ld\")\n",
    "            g.serialize(output_base_ttl + \".ttl\", format=\"turtle\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
