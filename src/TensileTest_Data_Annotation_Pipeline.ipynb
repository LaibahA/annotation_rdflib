{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensile Test Data Annotation Pipeline\n",
    "\n",
    "This notebook demonstrates how the script takes in a dataset input in JSON format, uses the TTO vocabulary to annotate the data in RDF triples with help from the RDFLib library, and finally serializes the annotated data into Turtle and JSON-LD formats."
   ],
   "id": "f8c411abbce34f3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, import the necessary packages.\n",
    "From rdflib we want to import graph which stores the RDF triples, namespace which allows us to define prefixes, and literal which helps with value formatting. We also want to import RDF, for standard datatypes, and XSD for when we want to serialize datatypes differently."
   ],
   "id": "c4c73744fd41af50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T19:49:04.212748Z",
     "start_time": "2025-07-25T19:49:04.123520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, json\n",
    "from rdflib import Graph, Namespace, Literal\n",
    "from rdflib.namespace import RDF, XSD"
   ],
   "id": "bfdbd9ba2d1a1c97",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we set the input and output directory path names. We should specify where to pull the input data from. The input data for this script should be in JSON format. Then, we specify where we want the annotated output datasets to go. We create two sets of outputs, one serialized with the Turtle format, and the other with the JSON-LD format. These two sets of annotated data go to separate directories as specified.",
   "id": "fde704f5e9cee9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T19:49:04.259958Z",
     "start_time": "2025-07-25T19:49:04.257330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"../data/FAIRtrain_data_json\"\n",
    "output_dir_jsonld = \"../output/annotatedBy_TTO/jsonld_output\"\n",
    "output_dir_ttl = \"../output/annotatedBy_TTO/ttl_output\""
   ],
   "id": "c27c5bc33631983a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we loop through each JSON file in the input directory. We want to create a new graph to store the RDF triples we will create for each file. Then, we create the prefixes for our namespaces, which just helps make it easier to use throughout the script.\n",
    "\n",
    "Next, we begin by making a list of the rows in the input file we are currently iterating over. We want to first create the necessary URIs to identify this specific test. We do so by first creating a URI for the tensile test itself using the sample id, then for the test piece, and finally for the machine group it belongs to. Using these URIs we then declare the test, test piece, and test machine by adding them to the graph we previously created as an RDF triple. Additionally, we establish relationships between the test piece and machine to the tensile test.\n",
    "\n",
    "It's important to note that since this script uses vocabulary from the TTO ontology, we are limited to using the \"relatesTo\" property to link concepts together. This will be prevalent throughout the rest of the script.\n",
    "\n",
    "Following this, we see that we are annotating the measured properties by creating a node or instance of it unique to this test, annotating it's type corresponding to the vocabulary we want to use from the TTO ontology, adding in the numeric value we read from the input while using the \"numeric value\" property from the QUDT ontology, and then finally relating it to the test/test piece to show the linkage.\n",
    "\n",
    "For the force and elongation pairs, since we are limited in our relationship vocabulary, the script creates each value as a node and then links a force and elongation node together to indicate that they are corresponding with each other.\n",
    "\n",
    "Finally, we serialize all this annotated data in turtle and json-ld and output to the specified directories."
   ],
   "id": "5826b7da0945ca24"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T19:52:13.977019Z",
     "start_time": "2025-07-25T19:49:04.589178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "        g = Graph()  #Empty graph to store triples\n",
    "\n",
    "        TTO = Namespace(\"https://materialdigital.github.io/application-ontologies/tto/#/\")\n",
    "        g.bind(\"tto\", TTO)\n",
    "        QUDT = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "        g.bind(\"qudt\", QUDT)\n",
    "\n",
    "        '''\n",
    "        Need to update namespace below to our domain\n",
    "        '''\n",
    "        EX = Namespace(\"http://example.org/tensile/\")  #This is an example, its gna be what builds the uri for our subject to annotate.\n",
    "        g.bind(\"ex\", EX)\n",
    "\n",
    "        with open(filepath) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            sample_id = data[\"sample_id\"]\n",
    "            test_uri = EX[sample_id]\n",
    "            test_piece_id = sample_id.split(\"_\")[2]\n",
    "            test_piece_uri = EX[\"testPiece_\" + test_piece_id]\n",
    "            machine_uri = EX[data[\"sample_id\"][:6]]\n",
    "\n",
    "            g.add((test_uri, RDF.type, TTO.TensileTest))\n",
    "            g.add((test_piece_uri, RDF.type, TTO.TestPiece))\n",
    "            g.add((machine_uri, RDF.type, TTO.TensileTestingMachine))\n",
    "\n",
    "            g.add((test_uri, TTO.relatesTo, test_piece_uri))\n",
    "            g.add((test_uri, TTO.relatesTo, machine_uri))\n",
    "\n",
    "            #Original width\n",
    "            #Creating a node to represent the concept of width for our data\n",
    "            width_node = EX[f\"width\"]\n",
    "            #Saying this node (subject) is a (predicate) object of this type (object)\n",
    "            g.add((width_node, RDF.type, TTO.OriginalWidth))\n",
    "            #Saying this node (subject) has numeric value (predicate) of this float (object)\n",
    "            g.add((width_node, QUDT.numericValue, Literal(data[\"width\"], datatype=XSD.float)))\n",
    "            #Saying this node (subject) is related to (predicate) the test piece (object)\n",
    "            g.add((width_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "            #Original thickness\n",
    "            thickness_node = EX[f\"thickness\"]\n",
    "            g.add((thickness_node, RDF.type, TTO.OriginalThickness))\n",
    "            g.add((thickness_node, QUDT.numericValue, Literal(data[\"thickness\"], datatype=XSD.float)))\n",
    "            g.add((thickness_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "            #Gauge length\n",
    "            length_node = EX[f\"length\"]\n",
    "            g.add((length_node, RDF.type, TTO.OriginalGaugeLength))\n",
    "            g.add((length_node, QUDT.numericValue, Literal(data[\"length\"], datatype=XSD.float)))\n",
    "            g.add((length_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "            #Youngs modulus / slope of the elastic part\n",
    "            youngs_mod_node = EX[f\"youngs_modulus\"]\n",
    "            g.add((youngs_mod_node, RDF.type, TTO.SlopeOfTheElasticPart))\n",
    "            g.add((youngs_mod_node, QUDT.numericValue, Literal(data[\"extracted_properties\"][\"youngs_modulus\"], datatype=XSD.float)))\n",
    "            g.add((youngs_mod_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "            #Ultimate tensile strength / upper yield strength\n",
    "            ult_tensile_strength = EX[f\"ultimate_tensile_strength\"]\n",
    "            g.add((ult_tensile_strength, RDF.type, TTO.UpperYieldStrength))\n",
    "            g.add((ult_tensile_strength, QUDT.numericValue, Literal(data[\"extracted_properties\"][\"ultimate_tensile_strength\"], datatype=XSD.float)))\n",
    "            g.add((ult_tensile_strength, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "            for i, point in enumerate(data[\"data\"]):\n",
    "                #Force\n",
    "                force_node = EX[f\"pair_{i}_force\"]\n",
    "                g.add((force_node, RDF.type, TTO.Force))\n",
    "                g.add((force_node, QUDT.numericValue, Literal(point[\"N\"], datatype=XSD.float)))\n",
    "                g.add((force_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "                #Elongation\n",
    "                elong_node = EX[f\"pair_{i}_elongation\"]\n",
    "                g.add((elong_node, RDF.type, TTO.Elongation))\n",
    "                g.add((elong_node, QUDT.numericValue, Literal(point[\"mm\"], datatype=XSD.float)))\n",
    "                g.add((elong_node, TTO.relatesTo, test_piece_uri))\n",
    "\n",
    "                #Pairing the elongation and force\n",
    "                g.add((elong_node, TTO.relatesTo, force_node))\n",
    "                g.add((force_node, TTO.relatesTo, elong_node))\n",
    "\n",
    "            output_base_jsonld = os.path.join(output_dir_jsonld, f\"annotated_{sample_id}\")\n",
    "            output_base_ttl = os.path.join(output_dir_ttl, f\"annotated_{sample_id}\")\n",
    "\n",
    "            #Serializing in jsonld and ttl\n",
    "            g.serialize(output_base_jsonld + \".jsonld\", format=\"json-ld\")\n",
    "            g.serialize(output_base_ttl + \".ttl\", format=\"turtle\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
